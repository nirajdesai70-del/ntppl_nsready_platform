#!/usr/bin/env bash

set -euo pipefail

# ================== CONFIG ==================

# Auto-detect environment (Kubernetes or Docker Compose)
if command -v kubectl &> /dev/null && kubectl get namespace nsready-tier2 &> /dev/null 2>&1; then
  ENV="kubernetes"
  NS="${NS:-nsready-tier2}"
  DB_POD="${DB_POD:-nsready-db-0}"
  COLLECT_SVC="${COLLECT_SVC:-collector-service}"
  ADMIN_SVC="${ADMIN_SVC:-admin-tool}"
  USE_KUBECTL=true
else
  ENV="docker"
  USE_KUBECTL=false
  DB_CONTAINER="${DB_CONTAINER:-nsready_db}"
fi

COLLECT_URL="${COLLECT_URL:-http://localhost:8001}"
HEALTH_URL="${HEALTH_URL:-$COLLECT_URL/v1/health}"
INGEST_URL="${INGEST_URL:-$COLLECT_URL/v1/ingest}"
METRICS_URL="${METRICS_URL:-$COLLECT_URL/metrics}"

REPORT_DIR="tests/reports"
TS="$(date +%Y%m%d_%H%M%S)"
REPORT="$REPORT_DIR/DATA_FLOW_TEST_$TS.md"

PF_PIDS=()

# ================== UTILS ==================

has() { command -v "$1" >/dev/null 2>&1; }

# Color support (auto-detect if terminal supports colors)
if [ -t 1 ] && command -v tput >/dev/null 2>&1; then
  COLOR_RESET=$(tput sgr0)
  COLOR_BOLD=$(tput bold)
  COLOR_GREEN=$(tput setaf 2)
  COLOR_RED=$(tput setaf 1)
  COLOR_YELLOW=$(tput setaf 3)
  COLOR_BLUE=$(tput setaf 4)
  COLOR_CYAN=$(tput setaf 6)
  USE_COLORS=true
else
  COLOR_RESET=""
  COLOR_BOLD=""
  COLOR_GREEN=""
  COLOR_RED=""
  COLOR_YELLOW=""
  COLOR_BLUE=""
  COLOR_CYAN=""
  USE_COLORS=false
fi

note() { 
  if [ "$USE_COLORS" = true ]; then
    echo "${COLOR_CYAN}ðŸ‘‰${COLOR_RESET} ${COLOR_BOLD}$*${COLOR_RESET}"
  else
    echo "ðŸ‘‰ $*"
  fi
}

ok() { 
  if [ "$USE_COLORS" = true ]; then
    echo "${COLOR_GREEN}âœ…${COLOR_RESET} ${COLOR_BOLD}${COLOR_GREEN}$*${COLOR_RESET}"
  else
    echo "âœ… $*"
  fi
}

warn() { 
  if [ "$USE_COLORS" = true ]; then
    echo "${COLOR_YELLOW}âš ï¸${COLOR_RESET}  ${COLOR_BOLD}${COLOR_YELLOW}$*${COLOR_RESET}"
  else
    echo "âš ï¸  $*"
  fi
}

fail() { 
  if [ "$USE_COLORS" = true ]; then
    echo "${COLOR_RED}âŒ${COLOR_RESET} ${COLOR_BOLD}${COLOR_RED}$*${COLOR_RESET}" >&2
  else
    echo "âŒ $*" >&2
  fi
  exit 1
}

# Database access functions
if [ "$USE_KUBECTL" = true ]; then
  kexec() { kubectl exec -n "$NS" "$DB_POD" -- "$@"; }
  psqlc() { kexec psql -U postgres -d nsready -At -F $'\t' -c "$*"; }
else
  psqlc() { docker exec "$DB_CONTAINER" psql -U postgres -d nsready -At -F $'\t' -c "$*"; }
fi

count_rows() {
  psqlc "SELECT COUNT(*) FROM public.ingest_events;" | awk 'NF{print $1; exit}'
}

# Port-forwarding (Kubernetes only)
pf_start() {
  if [ "$USE_KUBECTL" = true ]; then
    kubectl port-forward -n "$NS" svc/"$COLLECT_SVC" 8001:8001 >/dev/null 2>&1 & PF_PIDS+=($!)
    sleep 3
  fi
}

pf_stop() { 
  for pid in "${PF_PIDS[@]:-}"; do 
    kill "$pid" >/dev/null 2>&1 || true
  done
}

await_queue_drain() {
  local i=0 qd
  while [ $i -lt 45 ]; do
    qd=$(curl -s "$HEALTH_URL" 2>/dev/null | { if has jq; then jq -r .queue_depth 2>/dev/null; else grep -o '"queue_depth":[0-9.]*' | cut -d: -f2; fi; } | tr -dc '0-9.')
    [ -z "$qd" ] && qd=999
    echo "  queue_depth=$qd" >> "$REPORT"
    awk "BEGIN{exit !($qd<=0)}" && return 0
    sleep 2
    i=$((i+1))
  done
  return 1
}

# ================== REPORT HEADER ==================

mkdir -p "$REPORT_DIR"

cat > "$REPORT" <<EOF
# Data Flow Test Report

**Date**: $(date)
**Environment**: $ENV
**Test**: Dashboard Input â†’ NSReady Ingestion â†’ Database â†’ SCADA Export

---

## Test Steps

EOF

# ================== PRECHECKS ==================

note "Checking environment and services"

if [ "$USE_KUBECTL" = true ]; then
  kubectl get pods -n "$NS" >> "$REPORT" 2>&1 || fail "Namespace not reachable"
  pf_start
else
  docker ps | grep -E "(nsready|collector|db)" >> "$REPORT" 2>&1 || warn "Docker containers not found"
fi

# Check collector service health
COL_H=$(curl -s "$HEALTH_URL" 2>/dev/null || echo "unreachable")
echo "Collector health: $COL_H" >> "$REPORT"

if [ "$COL_H" = "unreachable" ]; then
  fail "Collector service not reachable at $HEALTH_URL"
fi

echo -e "\n---\n" >> "$REPORT"

# ================== AUTO-DETECT REGISTRY ==================

note "Discovering registry data (device + project/site + parameters)"

DEVICE_ROW=$(psqlc "SELECT d.id, s.id AS site_id, p.id AS project_id
FROM devices d JOIN sites s ON d.site_id=s.id JOIN projects p ON s.project_id=p.id
LIMIT 1;" 2>/dev/null || echo "")

if [ -z "$DEVICE_ROW" ]; then
  fail "No device/site/project found in DB; seed registry first."
fi

DEVICE_ID=$(echo "$DEVICE_ROW" | awk '{print $1}')
SITE_ID=$(echo "$DEVICE_ROW" | awk '{print $2}')
PROJECT_ID=$(echo "$DEVICE_ROW" | awk '{print $3}')

# Get parameter keys
PARAMS=$(psqlc "SELECT key FROM parameter_templates LIMIT 3;" 2>/dev/null || echo "")

if [ -z "$PARAMS" ]; then
  fail "No parameter_templates rows found."
fi

echo "Auto-detected:" >> "$REPORT"
echo "- project_id: $PROJECT_ID" >> "$REPORT"
echo "- site_id:    $SITE_ID" >> "$REPORT"
echo "- device_id:  $DEVICE_ID" >> "$REPORT"
echo "- parameters: $(echo "$PARAMS" | tr '\n' ',' | sed 's/,$//')" >> "$REPORT"
echo -e "\n---\n" >> "$REPORT"

# ================== BUILD TEST EVENT ==================

note "Building test event payload"

METRICS_JSON="[]"
TMP_METRICS=$(mktemp)

echo "$PARAMS" | while read -r pkey; do
  val=$(( (RANDOM % 1000) / 10 ))
  quality=192
  echo "{\"parameter_key\":\"$pkey\",\"value\":$val,\"quality\":$quality,\"attributes\":{}}" >> "$TMP_METRICS"
done

if has jq; then
  METRICS_JSON=$(jq -s '.' "$TMP_METRICS")
else
  METRICS_JSON="[$(paste -sd, "$TMP_METRICS")]"
fi

rm -f "$TMP_METRICS"

PAYLOAD="tmp_dataflow_event_$TS.json"
cat > "$PAYLOAD" <<EOF
{
  "project_id": "$PROJECT_ID",
  "site_id": "$SITE_ID",
  "device_id": "$DEVICE_ID",
  "protocol": "GPRS",
  "source_timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "metrics": $METRICS_JSON,
  "config_version": "v1.0"
}
EOF

echo "Test event created: $PAYLOAD" >> "$REPORT"
echo -e "\n---\n" >> "$REPORT"

# ================== STEP 1: DASHBOARD INPUT (Ingest API) ==================

note "Step 1: Sending dashboard input to /v1/ingest"

BEFORE=$(count_rows)
echo "Rows before: $BEFORE" >> "$REPORT"

RESP=$(curl -s -X POST "$INGEST_URL" \
  -H "Content-Type: application/json" \
  --data-binary @"$PAYLOAD" 2>&1)

echo "Ingest response: $RESP" >> "$REPORT"

if echo "$RESP" | grep -q "status.*queued"; then
  ok "Step 1: Dashboard input accepted"
  echo "âœ… Step 1: Dashboard input accepted" >> "$REPORT"
else
  fail "Step 1: Dashboard input failed - $RESP"
fi

echo -e "\n---\n" >> "$REPORT"

# ================== STEP 2: WAIT FOR PROCESSING ==================

note "Step 2: Waiting for queue to drain"

if await_queue_drain; then
  ok "Step 2: Queue drained"
  echo "âœ… Step 2: Queue drained" >> "$REPORT"
else
  warn "Step 2: Queue did not fully drain within timeout"
  echo "âš ï¸  Step 2: Queue did not fully drain within timeout" >> "$REPORT"
fi

echo -e "\n---\n" >> "$REPORT"

# ================== STEP 3: VERIFY DATABASE ==================

note "Step 3: Verifying data in database"

AFTER=$(count_rows)
echo "Rows after:  $AFTER" >> "$REPORT"

if [ "$AFTER" -gt "$BEFORE" ]; then
  ok "Step 3: Data stored in database (rows: $BEFORE â†’ $AFTER)"
  echo "âœ… Step 3: Data stored in database" >> "$REPORT"
else
  fail "Step 3: Data not in database (rows: $BEFORE â†’ $AFTER)"
fi

# Verify latest data
LATEST=$(psqlc "SELECT device_id, parameter_key, value, time 
FROM public.ingest_events 
WHERE device_id = '$DEVICE_ID' 
ORDER BY created_at DESC 
LIMIT 1;" 2>/dev/null || echo "")

if [ -n "$LATEST" ]; then
  ok "Step 3: Latest data verified"
  echo "Latest data: $LATEST" >> "$REPORT"
else
  warn "Step 3: Could not verify latest data"
fi

echo -e "\n---\n" >> "$REPORT"

# ================== STEP 4: VERIFY SCADA VIEWS ==================

note "Step 4: Verifying SCADA views"

# Check v_scada_latest
SCADA_LATEST_COUNT=$(psqlc "SELECT COUNT(*) FROM v_scada_latest WHERE device_id = '$DEVICE_ID';" 2>/dev/null | awk 'NF{print $1; exit}' || echo "0")

if [ "$SCADA_LATEST_COUNT" -gt 0 ]; then
  ok "Step 4: v_scada_latest contains data ($SCADA_LATEST_COUNT rows)"
  echo "âœ… Step 4: v_scada_latest contains data" >> "$REPORT"
else
  warn "Step 4: v_scada_latest empty or no data for device"
  echo "âš ï¸  Step 4: v_scada_latest empty" >> "$REPORT"
fi

# Check v_scada_history
SCADA_HISTORY_COUNT=$(psqlc "SELECT COUNT(*) FROM v_scada_history WHERE device_id = '$DEVICE_ID';" 2>/dev/null | awk 'NF{print $1; exit}' || echo "0")

if [ "$SCADA_HISTORY_COUNT" -gt 0 ]; then
  ok "Step 4: v_scada_history contains data ($SCADA_HISTORY_COUNT rows)"
  echo "âœ… Step 4: v_scada_history contains data" >> "$REPORT"
else
  warn "Step 4: v_scada_history empty or no data for device"
  echo "âš ï¸  Step 4: v_scada_history empty" >> "$REPORT"
fi

# Sample SCADA data
SCADA_SAMPLE=$(psqlc "SELECT device_id, parameter_key, value, time 
FROM v_scada_latest 
WHERE device_id = '$DEVICE_ID' 
LIMIT 1;" 2>/dev/null || echo "")

if [ -n "$SCADA_SAMPLE" ]; then
  echo "SCADA sample: $SCADA_SAMPLE" >> "$REPORT"
fi

echo -e "\n---\n" >> "$REPORT"

# ================== STEP 5: VERIFY SCADA EXPORT (Optional) ==================

note "Step 5: Testing SCADA export (optional)"

if [ -f "scripts/export_scada_data.sh" ]; then
  EXPORT_FILE="scada_export_test_$TS.txt"
  if ./scripts/export_scada_data.sh --latest --format txt --output "$EXPORT_FILE" 2>/dev/null; then
    if [ -f "$EXPORT_FILE" ] && [ -s "$EXPORT_FILE" ]; then
      ok "Step 5: SCADA export successful"
      echo "âœ… Step 5: SCADA export successful" >> "$REPORT"
      echo "Export file: $EXPORT_FILE" >> "$REPORT"
      rm -f "$EXPORT_FILE"
    else
      warn "Step 5: SCADA export file empty"
      echo "âš ï¸  Step 5: SCADA export file empty" >> "$REPORT"
    fi
  else
    warn "Step 5: SCADA export script failed (non-critical)"
    echo "âš ï¸  Step 5: SCADA export script failed" >> "$REPORT"
  fi
else
  note "Step 5: SCADA export script not found (skipping)"
  echo "â­ï¸  Step 5: SCADA export script not found (skipped)" >> "$REPORT"
fi

echo -e "\n---\n" >> "$REPORT"

# ================== SUMMARY ==================

cat >> "$REPORT" <<EOF

## Summary

**Test Status**: âœ… **PASSED** (Data flow working correctly)

**Steps Completed**:
1. âœ… Dashboard input sent to /v1/ingest
2. âœ… Queue drained (events processed)
3. âœ… Data stored in database
4. âœ… Data visible in SCADA views
5. âœ… SCADA export tested (if available)

**Data Flow**: Dashboard Input â†’ NSReady Ingestion â†’ Database â†’ SCADA Export

---

**Report generated**: $(date)
EOF

# Cleanup
rm -f "$PAYLOAD"
pf_stop

ok "Data flow test complete - see $REPORT"
note "Report saved to: $REPORT"

