# NOTE / INTENT
# ----------------------------------------------------------------------------------
# This workflow is responsible for:
#   - Building backend artifacts/images
#   - Deploying them to the target environment (local/staging/prod)
#   - Running LIGHT SMOKE CHECKS against the deployed services
#
# It is NOT the primary backend test harness.
# Full backend Baseline Set (data flow, batch, stress) is defined and maintained in:
#   - .github/workflows/backend_tests.yml
#   - nsready_backend/tests/README_BACKEND_TESTS.md
#
# If you need to change how backend tests run:
#   1. Update the SOP (README_BACKEND_TESTS.md)
#   2. Update backend_tests.yml
#   3. Keep this file focused on deploy + health checks only.
# ----------------------------------------------------------------------------------

name: Build, Test, and Deploy

on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main

env:
  REGISTRY: ghcr.io
  IMAGE_PREFIX: ${{ github.repository_owner }}/nsready

# Workflow validation: ensure jobs are properly defined

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          # Note: Update path if tests/requirements.txt moved
          if [ -f "nsready_backend/tests/requirements.txt" ]; then
            pip install -r nsready_backend/tests/requirements.txt
          elif [ -f "tests/requirements.txt" ]; then
            pip install -r tests/requirements.txt
          else
            echo "⚠️  No requirements.txt found; skipping pip install"
          fi

      - name: Run Python tests (if available)
        run: |
          # Note: Update path if tests moved
          if [ -f "Makefile" ] && grep -q "test:" Makefile; then
            make test || echo "⚠️  Python tests failed; continuing with deploy"
          else
            echo "⚠️  No Python test target found; skipping"
          fi
        env:
          DOCKER_COMPOSE_CMD: docker compose
        continue-on-error: true  # Don't block deploy if Python tests fail

      # NOTE: Full backend Baseline Set tests are now run in backend_tests.yml
      # This workflow assumes those tests have passed and only runs deploy + smoke checks

      - name: Run benchmarks
        run: |
          make benchmark
        continue-on-error: true

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GHCR_TOKEN }}

      - name: Extract metadata for admin-tool
        id: meta-admin
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}-admin-tool
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,format=short,prefix=sha-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Extract metadata for collector-service
        id: meta-collector
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}-collector-service
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=semver,pattern={{version}}
            type=semver,pattern={{major}}.{{minor}}
            type=sha,format=short,prefix=sha-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push admin-tool image
        uses: docker/build-push-action@v5
        with:
          context: ./nsready_backend/admin_tool
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta-admin.outputs.tags }}
          labels: ${{ steps.meta-admin.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build and push collector-service image
        uses: docker/build-push-action@v5
        with:
          context: ./nsready_backend/collector_service
          push: ${{ github.event_name != 'pull_request' }}
          tags: ${{ steps.meta-collector.outputs.tags }}
          labels: ${{ steps.meta-collector.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    needs: build-and-test
    runs-on: ubuntu-latest
    if: ${{ github.ref == 'refs/heads/main' && github.event_name == 'push' }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: 'latest'

      - name: Set up Helm
        uses: azure/setup-helm@v3
        with:
          version: 'latest'

      - name: Configure kubectl
        run: |
          if [ -z "${{ secrets.KUBECONFIG }}" ]; then
            echo "⚠️  KUBECONFIG secret not set; skipping deployment"
            exit 0
          fi
          mkdir -p $HOME/.kube
          echo "${{ secrets.KUBECONFIG }}" | base64 -d > $HOME/.kube/config
          kubectl config set-context --current --namespace=nsready-tier2
          
          # Check if cluster is accessible (skip if local cluster like Docker Desktop)
          if ! kubectl cluster-info > /dev/null 2>&1; then
            echo "⚠️  Cannot connect to Kubernetes cluster (may be local cluster not accessible from CI)"
            echo "⚠️  Skipping deployment - this is expected for local Docker Desktop clusters"
            exit 0
          fi
          
          kubectl cluster-info

      - name: Deploy to Kubernetes
        run: |
          # Update image tags in values.yaml
          # Note: Update path if deploy/helm moved
          HELM_VALUES="shared/deploy/helm/nsready/values.yaml"
          if [ ! -f "$HELM_VALUES" ]; then
            HELM_VALUES="deploy/helm/nsready/values.yaml"
          fi
          
          if [ -f "$HELM_VALUES" ]; then
            sed -i "s|tag: latest|tag: ${{ github.sha }}|g" "$HELM_VALUES"
            sed -i "s|imageRegistry:.*|imageRegistry: ${{ env.REGISTRY }}/${{ env.IMAGE_PREFIX }}|g" "$HELM_VALUES"
            
            # Deploy using Helm
            HELM_CHART="shared/deploy/helm/nsready"
            if [ ! -d "$HELM_CHART" ]; then
              HELM_CHART="deploy/helm/nsready"
            fi
            
            helm upgrade --install nsready "$HELM_CHART" \
              --namespace nsready-tier2 \
              --create-namespace \
              --set secrets.postgresPassword="${{ secrets.POSTGRES_PASSWORD }}" \
              --set secrets.jwtSecret="${{ secrets.JWT_SECRET }}" \
              --set secrets.natsToken="${{ secrets.NATS_TOKEN }}" \
              --wait \
              --timeout 10m
          else
            echo "⚠️  Helm chart not found; skipping Kubernetes deploy"
          fi

      - name: Verify deployment
        run: |
          kubectl get pods -n nsready-tier2
          kubectl get services -n nsready-tier2
          kubectl rollout status deployment/admin-tool -n nsready-tier2 || echo "⚠️  admin-tool rollout check skipped"
          kubectl rollout status deployment/collector-service -n nsready-tier2 || echo "⚠️  collector-service rollout check skipped"

      # --------------------------------------------------------------------------------
      # Post-deploy smoke checks
      # --------------------------------------------------------------------------------
      # These steps only verify that deployed services are alive and responding:
      #   - admin_tool  (e.g. http://localhost:8000/health)
      #   - collector_service (e.g. http://localhost:8001/health)
      #
      # They are NOT a replacement for the backend Baseline Set tests.
      # Full backend tests are already run in backend_tests.yml.
      # --------------------------------------------------------------------------------

      - name: Health check - admin_tool
        run: |
          set -e
          echo "Setting up port-forward for admin_tool..."
          kubectl port-forward deployment/admin-tool -n nsready-tier2 8000:8000 > /tmp/admin-portforward.log 2>&1 &
          PF_ADMIN_PID=$!
          sleep 5
          
          echo "Waiting for admin_tool health endpoint..."
          for i in {1..30}; do
            if curl -fsS http://localhost:8000/health > /dev/null 2>&1; then
              echo "✅ admin_tool is healthy."
              kill $PF_ADMIN_PID 2>/dev/null || true
              exit 0
            fi
            echo "⏳ admin_tool not healthy yet, retrying in 5s... (attempt $i/30)"
            sleep 5
          done
          
          echo "❌ admin_tool did not become healthy in time."
          echo "--- admin_tool logs ---"
          kubectl logs -n nsready-tier2 deployment/admin-tool --tail=50 || echo "admin_tool logs not available."
          kill $PF_ADMIN_PID 2>/dev/null || true
          exit 1
        continue-on-error: false

      - name: Health check - collector_service
        run: |
          set -e
          echo "Setting up port-forward for collector_service..."
          kubectl port-forward deployment/collector-service -n nsready-tier2 8001:8001 > /tmp/collector-portforward.log 2>&1 &
          PF_COLLECTOR_PID=$!
          sleep 5
          
          echo "Waiting for collector_service health endpoint..."
          for i in {1..30}; do
            if curl -fsS http://localhost:8001/v1/health > /dev/null 2>&1; then
              HEALTH_RESPONSE=$(curl -s http://localhost:8001/v1/health)
              echo "✅ collector_service is healthy: $HEALTH_RESPONSE"
              kill $PF_COLLECTOR_PID 2>/dev/null || true
              exit 0
            fi
            echo "⏳ collector_service not healthy yet, retrying in 5s... (attempt $i/30)"
            sleep 5
          done
          
          echo "❌ collector_service did not become healthy in time."
          echo "--- collector_service logs ---"
          kubectl logs -n nsready-tier2 deployment/collector-service --tail=50 || echo "collector_service logs not available."
          kill $PF_COLLECTOR_PID 2>/dev/null || true
          exit 1
        continue-on-error: false


